{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Spob7B8dvO6"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/pt/a/a2/Brasao_UFPA.jpg\" width=\"300\">\n",
        "\n",
        "  # **Universidade Federal do Par√°**\n",
        "  ## **Instituto de Tecnologia**\n",
        "  ### **Faculdade de Engenharia de Computa√ß√£o e Telecomunica√ß√µes**\n",
        "\n",
        "  ---\n",
        "\n",
        "  # **Disciplina:** Intelig√™ncia Computacional\n",
        "  ### **Professor:** Dr. Aldebaro Barreto da Rocha Klautau Jr.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ## üìë **Tema:** Aplica√ß√µes B√°sicas de *Recupera√ß√£o Aumentada por Gera√ß√£o* (RAG)\n",
        "\n",
        "</div>\n",
        "\n",
        "**Data:** 12 de Fevereiro de 2026  \n",
        "\n",
        "---\n",
        "\n",
        "### **Resumo do Notebook**\n",
        "\n",
        "\n",
        "**Pacote necess√°rio:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXqjwQkzekNg"
      },
      "source": [
        "[Milvus](https://milvus.io/) √© um banco de dados vetorial de c√≥digo aberto popular que impulsiona aplica√ß√µes de IA com busca de similaridade vetorial altamente perform√°tica e escal√°vel. Neste tutorial, mostraremos como construir um pipeline RAG (Retrieval-Augmented Generation - Gera√ß√£o Aumentada por Recupera√ß√£o) com Hugging Face e Milvus.\n",
        "\n",
        "O sistema RAG combina um sistema de recupera√ß√£o com um LLM (Learning Learning Machine - M√°quina de Aprendizagem de Lideran√ßa). O sistema primeiro recupera documentos relevantes de um corpus usando o banco de dados vetorial Milvus e, em seguida, usa um LLM hospedado no Hugging Face para gerar respostas com base nos documentos recuperados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvaujL6pe9pH"
      },
      "source": [
        "## **1 - Prepara√ß√£o**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBm6oQJMfAWw"
      },
      "source": [
        "### **1.1 - Depend√™ncias e Ambiente**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlE_7Gwe2x0F",
        "outputId": "075d0f7c-d75b-41b9-a0da-dfa5d141bf3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (1.4.1)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.3)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.0.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (0.21.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.2.9)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.46)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.9)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub) (0.16.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub) (8.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade sentence-transformers huggingface-hub langchain_community langchain-text-splitters pypdf tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlf8XQzMly7c",
        "outputId": "ed671adf-85e1-4cc6-f1fa-29e4b99dd0ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymilvus in /usr/local/lib/python3.12/dist-packages (2.6.9)\n",
            "Collecting milvus-lite\n",
            "  Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (75.2.0)\n",
            "Requirement already satisfied: grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (1.76.0)\n",
            "Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (3.11.7)\n",
            "Requirement already satisfied: protobuf>=5.27.2 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (5.29.6)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (1.2.1)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (2.2.2)\n",
            "Requirement already satisfied: cachetools>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from milvus-lite) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2->pymilvus) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n",
            "Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl (55.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.3/55.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: milvus-lite\n",
            "Successfully installed milvus-lite-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pymilvus milvus-lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydeQCV2SfQhG"
      },
      "source": [
        "Al√©m disso, recomendamos que voc√™ configure seu [Token de Acesso de Usu√°rio do Hugging Face](https://huggingface.co/docs/hub/security-tokens) e o defina em suas vari√°veis ‚Äã‚Äãde ambiente, pois usaremos um LLM do Hugging Face Hub. Voc√™ poder√° ter um limite baixo de solicita√ß√µes se n√£o configurar a vari√°vel de ambiente do token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sawYs6_o2_Lt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = \"hf_...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP__WEznfq4y"
      },
      "source": [
        "### **1.2 - Preparar os dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ZQtHQcftaN"
      },
      "source": [
        "Utilizamos o [AI Act PDF](https://artificialintelligenceact.eu/wp-content/uploads/2021/08/The-AI-Act.pdf), um quadro regulamentar para IA com diferentes n√≠veis de risco correspondentes a mais ou menos regulamenta√ß√£o, como conhecimento privado em nosso RAG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6edA1RBOf-3j"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "if [ ! -f \"The-AI-Act.pdf\" ]; then\n",
        "    wget -q https://artificialintelligenceact.eu/wp-content/uploads/2021/08/The-AI-Act.pdf\n",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evH9jAkTgGau"
      },
      "source": [
        "Utilizamos o [`PyPDFLoader`](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/pdf/) do LangChain para extrair o texto do PDF e, em seguida, dividimos o texto em partes menores. Por padr√£o, definimos o tamanho da parte como 1000 e a sobreposi√ß√£o como 200, o que significa que cada parte ter√° aproximadamente 1000 caracteres e a sobreposi√ß√£o entre duas partes ser√° de 200 caracteres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZiEE7xggVh7",
        "outputId": "87e982aa-47bc-4d41-fc82-bade5f9783ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"The-AI-Act.pdf\")\n",
        "docs = loader.load()\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wOvR6racgra3"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Kozyd12tgyRY"
      },
      "outputs": [],
      "source": [
        "text_lines = [chunk.page_content for chunk in chunks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "w2UCnSeAgzed",
        "outputId": "3b0898f4-fb44-4354-8972-0536a0981749"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'EN   EN \\n \\n \\n \\nEUROPEAN \\nCOMMISSION  \\nBrussels, 21.4.2021  \\nCOM(2021) 206 final \\n2021/0106 (COD) \\n \\nProposal for a \\nREGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL \\nLAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE \\n(ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION \\nLEGISLATIVE ACTS \\n{SEC(2021) 167 final} - {SWD(2021) 84 final} - {SWD(2021) 85 final}'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_lines[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBnY-T_1g--E"
      },
      "source": [
        "### **1.3 - Preparar o Modelo de Incorpora√ß√£o**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPxtJMWjh1o-"
      },
      "source": [
        "Defina uma fun√ß√£o para gerar embeddings de texto. Usamos o [modelo de embedding BGE](https://huggingface.co/BAAI/bge-small-en-v1.5) como exemplo, mas voc√™ pode usar qualquer modelo de embedding, como os encontrados no [ranking MTEB](https://huggingface.co/spaces/mteb/leaderboard)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "179ffbf3e4fc449fac82cb5d1a3c445b",
            "b1b6347ba7a14b6f8b76707c85bd06fa",
            "856e94ecdbee4334a96dc38c03f0aed8",
            "71078973bdd9460ba62bede8db03d50a",
            "d7fbd2b3ca794cddb57fd53d3ddf899e",
            "98fed681acd54bd7853f491b20fe8981",
            "df555e0755884fd1afecfc099ff58937",
            "c60dd40f2e3643f8bb0789a6a394d041",
            "2381e0eab3bb41878827e93b4d1475da",
            "1ac497de09e94246b9a3607869c96be5",
            "51dc71e77a524707b1eb93bd13ea23e5"
          ]
        },
        "id": "vTbPVqisiJQ8",
        "outputId": "2431c15a-253e-4d5a-d32e-4a338769d6a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "179ffbf3e4fc449fac82cb5d1a3c445b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertModel LOAD REPORT from: BAAI/bge-small-en-v1.5\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedding_model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "def emb_text(text):\n",
        "    return embedding_model.encode([text], normalize_embeddings=True).tolist()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvlNWK04ihJl"
      },
      "source": [
        "Gere um vetor de teste e imprima suas dimens√µes e os primeiros elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MVx_F6QixAk",
        "outputId": "67ef0b81-becf-48fb-c992-7a887a95d787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "384\n",
            "[-0.07660680264234543, 0.02531673200428486, 0.012505538761615753, 0.004595177713781595, 0.025780003517866135, 0.038167089223861694, 0.08050810545682907, 0.0030353753827512264, 0.02439218945801258, 0.004880349617451429]\n"
          ]
        }
      ],
      "source": [
        "test_embedding = emb_text(\"This is a test\")\n",
        "embedding_dim = len(test_embedding)\n",
        "print(embedding_dim)\n",
        "print(test_embedding[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41T5M4AmjJLy"
      },
      "source": [
        "## **2 - Carregar dados no Milvus**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huGYW_uwjVyb"
      },
      "source": [
        "### **2.1 - Criar a Cole√ß√£o**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rQr9GSbjYjb",
        "outputId": "626ec983-693d-456b-be66-1d78573aa9e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conectado com sucesso!\n"
          ]
        }
      ],
      "source": [
        "from pymilvus import MilvusClient\n",
        "\n",
        "milvus_client = MilvusClient(uri=\"./hf_milvus_demo.db\")\n",
        "collection_name = \"rag_collection\"\n",
        "print(\"Conectado com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktzHxKHnjke9"
      },
      "source": [
        "> Quanto ao argumento de `MilvusClient`:\n",
        "> - Definir o `uri` como um arquivo local, por exemplo, `./hf_milvus_demo.db`, ‚Äã‚Äã√© o m√©todo mais conveniente, pois utiliza automaticamente o [Milvus Lite](https://milvus.io/docs/milvus_lite.md) para armazenar todos os dados neste arquivo.\n",
        "> - Se voc√™ tiver uma grande quantidade de dados, digamos, mais de um milh√£o de vetores, voc√™ pode configurar um servidor Milvus mais eficiente no [Docker ou Kubernetes](https://milvus.io/docs/quickstart.md). Nessa configura√ß√£o, use o URI do servidor, por exemplo, `http://localhost:19530`, como seu `uri`.\n",
        "\n",
        "> - Se voc√™ quiser usar o [Zilliz Cloud](https://zilliz.com/cloud), o servi√ßo de nuvem totalmente gerenciado para Milvus, ajuste o `uri` e o `token`, que correspondem ao [Endpoint P√∫blico e chave de API](https://docs.zilliz.com/docs/on-zilliz-cloud-console#cluster-details) no Zilliz Cloud.\n",
        "\n",
        "---\n",
        "\n",
        "**Aten√ß√£o:** Como o disco do Colab √© tempor√°rio, se voc√™ fechar a aba e voltar amanh√£, esse arquivo `.db` ter√° sumido. Se voc√™ estiver guardando dados importantes, recomendo salvar esse arquivo no seu Google Drive montado:\n",
        "\n",
        "```python\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Use um caminho dentro do seu Drive para n√£o perder os dados\n",
        "milvus_client = MilvusClient(uri=\"/content/drive/MyDrive/milvus_demo.db\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "Verifique se a cole√ß√£o j√° existe e, se existir, remova-a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YMTKiSrFj2Se"
      },
      "outputs": [],
      "source": [
        "if milvus_client.has_collection(collection_name):\n",
        "    milvus_client.drop_collection(collection_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CN3RWIXmImn"
      },
      "source": [
        "Crie uma nova cole√ß√£o com os par√¢metros especificados.\n",
        "\n",
        "Se n√£o especificarmos nenhuma informa√ß√£o de campo, o Milvus criar√° automaticamente um campo `id` padr√£o para a chave prim√°ria e um campo `vector` para armazenar os dados do vetor. Um campo JSON reservado √© usado para armazenar campos n√£o definidos no esquema e seus valores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V8AQk9snmHIC"
      },
      "outputs": [],
      "source": [
        "milvus_client.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    dimension=embedding_dim,\n",
        "    metric_type=\"IP\",\n",
        "    consistency_level=\"Strong\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu8InrqOmqiG"
      },
      "source": [
        "### **2.2 - Inserir dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuU52kFEmyLn"
      },
      "source": [
        "Percorra as linhas de texto, crie embeddings e insira os dados no Milvus.\n",
        "\n",
        "Aqui est√° um novo campo `text`, que n√£o est√° definido no esquema da cole√ß√£o. Ele ser√° adicionado automaticamente aos campos din√¢micos JSON reservados, podendo ser tratado como um campo normal em um n√≠vel mais alto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8nSx8h-m2u6",
        "outputId": "f869e32b-9670-41db-da70-459d4a954bc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 424/424 [01:54<00:00,  3.71it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "424"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "data = []\n",
        "\n",
        "for i, line in enumerate(tqdm(text_lines, desc=\"Creating embeddings\")):\n",
        "    data.append({\"id\": i, \"vector\": emb_text(line), \"text\": line})\n",
        "\n",
        "insert_res = milvus_client.insert(collection_name=collection_name, data=data)\n",
        "insert_res[\"insert_count\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF8jTgAAm-0T"
      },
      "source": [
        "## **3 - Construir RAG**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5UL4r60m_j7"
      },
      "source": [
        "### **3.1 - Recuperar dados para uma consulta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zUVUZ_hnPAs"
      },
      "source": [
        "Vamos especificar uma pergunta a ser feita sobre o corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "YCn4LpTZnR1a"
      },
      "outputs": [],
      "source": [
        "question = \"What is the legal basis for the proposal?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nXZ9446nUez"
      },
      "source": [
        "Pesquise a pergunta na cole√ß√£o e recupere as 3 principais correspond√™ncias sem√¢nticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "u_os9YIQnY1D"
      },
      "outputs": [],
      "source": [
        "search_res = milvus_client.search(\n",
        "    collection_name=collection_name,\n",
        "    data=[\n",
        "        emb_text(question)\n",
        "    ],  # Use the `emb_text` function to convert the question to an embedding vector\n",
        "    limit=3,  # Return top 3 results\n",
        "    search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n",
        "    output_fields=[\"text\"],  # Return the text field\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBFBR99SnbxG"
      },
      "source": [
        "Vamos analisar os resultados da pesquisa:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3oHa8aunix6",
        "outputId": "765cac1c-dead-4d3a-a2f1-6e388f23653a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    [\n",
            "        \"EN 6  EN \\n2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY \\n2.1. Legal basis \\nThe legal basis for the proposal is in the first place Article 114 of the Treaty on the \\nFunctioning of the European Union (TFEU), which provides for the adoption of measures to \\nensure the establishment and functioning of the internal market.  \\nThis proposal constitutes a core part of the EU digital single market strategy. The primary \\nobjective of this proposal is to ensure the proper functioning of the internal market by setting \\nharmonised rules in particular on the development, placing on the Union market and the use \\nof products and services making use of AI technologies or provided as stand -alone AI \\nsystems. Some Member States are already considering national rules to ensure that AI is safe \\nand is developed and used in compliance with fundamental rights obligations. This will likely \\nlead to two main problems: i) a fragmentation of the internal market on essential elements\",\n",
            "        0.7306114435195923\n",
            "    ],\n",
            "    [\n",
            "        \"applications and prevent market fragmentation. \\nTo achieve those objectives, this proposal presents a balanced and proportionate horizontal \\nregulatory approach to AI that is limited to the minimum necessary requirements to address \\nthe risks and problems linked to AI, withou t unduly constraining or hindering technological \\ndevelopment or otherwise disproportionately increasing the cost of placing AI solutions on \\nthe market. The proposal sets a robust and flexible legal framework. On the one hand, it is \\ncomprehensive and future -proof in its fundamental regulatory choices, including the \\nprinciple-based requirements that AI systems should comply with. On the other hand, it puts \\nin place a proportionate regulatory system centred on a well -defined risk -based regulatory \\napproach that does not create unnecessary restrictions to trade, whereby legal intervention is \\ntailored to those concrete situations where there is a justified cause for concern or where such\",\n",
            "        0.6964290738105774\n",
            "    ],\n",
            "    [\n",
            "        \"approach that does not create unnecessary restrictions to trade, whereby legal intervention is \\ntailored to those concrete situations where there is a justified cause for concern or where such \\nconcern can reasonably be anticipated in the near future. At the same time, t he legal \\nframework includes flexible mechanisms that enable it to be dynamically adapted as the \\ntechnology evolves and new concerning situations emerge. \\nThe proposal sets harmonised rules for the development, placement on the market and use of \\nAI systems i n the Union following a proportionate risk -based approach. It proposes a single \\nfuture-proof definition of AI. Certain particularly harmful AI practices are prohibited as \\ncontravening Union values, while specific restrictions and safeguards are proposed in  relation \\nto certain uses of remote biometric identification systems for the purpose of law enforcement. \\nThe proposal lays down a solid risk methodology to define \\u201chigh -risk\\u201d AI systems that pose\",\n",
            "        0.6891460418701172\n",
            "    ]\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "retrieved_lines_with_distances = [\n",
        "    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n",
        "]\n",
        "print(json.dumps(retrieved_lines_with_distances, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArMqCl_snibe"
      },
      "source": [
        "### **3.2 - Use LLM para obter uma resposta RAG**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V6vbQvpn3_i"
      },
      "source": [
        "Antes de compor o prompt para o LLM, vamos primeiro transformar a lista de documentos recuperada em uma string simples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "JkhazBOXn8cq"
      },
      "outputs": [],
      "source": [
        "context = \"\\n\".join(\n",
        "    [line_with_distance[0] for line_with_distance in retrieved_lines_with_distances]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B02cUgfwoBRi"
      },
      "source": [
        "Defina os prompts para o Modelo de Linguagem. Este prompt √© montado com os documentos recuperados do Milvus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Jc-NW55SoDTm"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"\"\"\n",
        "Utilize as informa√ß√µes a seguir, entre tags <context>, para responder √† pergunta entre tags <question>.\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "<question>\n",
        "{question}\n",
        "</question>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "K9hLKNBsqSQY"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"Voc√™ √© um assistente acad√™mico. Responda em Portugu√™s (Brasil) com base no contexto fornecido.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": PROMPT.format(context=context, question=question)\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvca6fpDoKxN"
      },
      "source": [
        "Utilizamos o modelo [Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) da Meta, acessado via API de Infer√™ncia da Hugging Face, para gerar respostas baseadas em um sistema de mensagens estruturadas (Chat Completion)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "qoRPI0UyoOpl"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "repo_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "llm_client = InferenceClient(model=repo_id, timeout=120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsetxQwsoVGH"
      },
      "source": [
        "Finalmente, podemos formatar o enunciado e gerar a resposta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JjStuHFoh4e",
        "outputId": "4b26dc6c-1b22-4e23-df4c-eada3691aea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- RESPOSTA ---\n",
            "A base legal para a proposta est√°, em primeiro lugar, no Artigo 114 do Tratado sobre o Funcionamento da Uni√£o Europeia (TFEU), que prev√™ a ado√ß√£o de medidas para garantir a estabelecimento e o funcionamento do mercado interior.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # O chat_completion enviar√° automaticamente o seu HF_TOKEN configurado\n",
        "    response = llm_client.chat_completion(\n",
        "        messages=messages,\n",
        "        max_tokens=1000,\n",
        "        temperature=0.3\n",
        "    )\n",
        "    answer = response.choices[0].message.content.strip()\n",
        "    print(\"--- RESPOSTA ---\")\n",
        "    print(answer)\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao chamar a API: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHmR7rdhoerm"
      },
      "source": [
        "Parab√©ns! Voc√™ criou um pipeline RAG com Hugging Face e Milvus."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "179ffbf3e4fc449fac82cb5d1a3c445b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1b6347ba7a14b6f8b76707c85bd06fa",
              "IPY_MODEL_856e94ecdbee4334a96dc38c03f0aed8",
              "IPY_MODEL_71078973bdd9460ba62bede8db03d50a"
            ],
            "layout": "IPY_MODEL_d7fbd2b3ca794cddb57fd53d3ddf899e"
          }
        },
        "1ac497de09e94246b9a3607869c96be5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2381e0eab3bb41878827e93b4d1475da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51dc71e77a524707b1eb93bd13ea23e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71078973bdd9460ba62bede8db03d50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ac497de09e94246b9a3607869c96be5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_51dc71e77a524707b1eb93bd13ea23e5",
            "value": "‚Äá199/199‚Äá[00:00&lt;00:00,‚Äá396.16it/s,‚ÄáMaterializing‚Äáparam=pooler.dense.weight]"
          }
        },
        "856e94ecdbee4334a96dc38c03f0aed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c60dd40f2e3643f8bb0789a6a394d041",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2381e0eab3bb41878827e93b4d1475da",
            "value": 199
          }
        },
        "98fed681acd54bd7853f491b20fe8981": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1b6347ba7a14b6f8b76707c85bd06fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98fed681acd54bd7853f491b20fe8981",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_df555e0755884fd1afecfc099ff58937",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "c60dd40f2e3643f8bb0789a6a394d041": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fbd2b3ca794cddb57fd53d3ddf899e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df555e0755884fd1afecfc099ff58937": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
